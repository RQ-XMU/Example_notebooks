{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General explanation\n",
    "Building neural networks with TensorFlow, without Keras for MNIST data.\n",
    "MNIST contains 55000 images of digit 0...9. The task is to build a model that predict digit for a given image.\n",
    "Each image in MNIST is 28x28x1 mean 28 pixels width, 28 pixels heigh and 1 color channel, - gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and see some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-93d8da72a918>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST object overview:\n",
      " Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fef05158940>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7feed176f400>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7feed176f860>)\n",
      "==================================================\n",
      "Train set shape:\n",
      " (55000, 784)\n",
      "==================================================\n",
      "Test set shape:\n",
      " (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"MNIST object overview:\\n\", mnist)\n",
    "print('='*50)\n",
    "print(\"Train set shape:\\n\", mnist.train.images.shape)\n",
    "print('='*50)\n",
    "print(\"Test set shape:\\n\", mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fe1e925f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_indices = [1,2,3,4]\n",
    "train_samples = mnist.train.images[sample_indices]\n",
    "labes_samples = mnist.train.labels[sample_indices]\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(len(sample_indices)):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%labes_samples[i].argmax(axis=-1))\n",
    "    plt.imshow(train_samples[i].reshape([28,28]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiLayer Perceptron\n",
    "## Architexture\n",
    "\n",
    "- 1. Input [batch, 724 = 28x28], **x** <br>\n",
    "- 2.1. Linear summator 1, 200 units, **Z1**\n",
    "- 2.2. Activator 1, ReLU/sigmoid, **A1** <br>\n",
    "- 3.1. Linear summator 2, 100 units, **Z2**\n",
    "- 3.2. Activator 2, ReLU/sigmoid, **A2** <br>\n",
    "- 4.1. Linear summator 3, 10 units, **Z3** \n",
    "- 4.2. Activator 3, ReLU/sigmoid, **A3**\n",
    "- 5. softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "# build computational graph\n",
    "# ============================================================\n",
    "\n",
    "# input layer\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "# None means we do not define how many batch size\n",
    "# ============================================================\n",
    "\n",
    "# Weight and bias matrices for fist summator with 200 units\n",
    "W12 = tf.Variable(tf.random_normal(shape=[784, 200]))\n",
    "b1 = tf.Variable(tf.zeros([200]))\n",
    "\n",
    "# initialize variables for W12 & b1\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# first summator\n",
    "Z1 = tf.matmul(x, W12) + b1\n",
    "\n",
    "# First activator with sigmoid function\n",
    "A1 = tf.nn.sigmoid(Z1)\n",
    "\n",
    "# ============================================================\n",
    "# Weight and bias matrices for second summator with 100 units\n",
    "W23 = tf.Variable(tf.random_normal(shape=[200, 100]))\n",
    "b2 = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "# initialize variables for W23 & b2\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# second summator\n",
    "Z2 = tf.matmul(A1, W23) + b2\n",
    "\n",
    "# secon activator with sigmoid function\n",
    "A2 = tf.nn.sigmoid(Z2)\n",
    "\n",
    "# ============================================================\n",
    "# Weight and bias matrices for third summator with 10 units\n",
    "W34 = tf.Variable(tf.zeros(shape=[100, 10]))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# initialize variables for W34 & b3\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# third summator\n",
    "Z3 = tf.matmul(A2, W34) + b3\n",
    "\n",
    "# third activator with sigmoid function\n",
    "A3 = tf.nn.sigmoid(Z3)\n",
    "# ============================================================\n",
    "# labels\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=A3)\n",
    ")\n",
    "\n",
    "# model training aim is minimize cost function by mini-batch gradient descent\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1)\\\n",
    "                     .minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training - computational graph\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7092\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "correct_prediction = tf.equal(tf.argmax(A3,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "# was 0.9189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7041091\n"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP: Input + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "# build computational graph\n",
    "# ============================================================\n",
    "\n",
    "# input layer\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "# None means we do not define how many batch size\n",
    "# ============================================================\n",
    "\n",
    "# Weight and bias matrices for fist summator with 200 units\n",
    "W12 = tf.Variable(tf.zeros(shape=[784, 10]))\n",
    "b1 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# initialize variables for W12 & b1\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# first summator\n",
    "Z1 = tf.matmul(x, W12) + b1\n",
    "\n",
    "# First activator with sigmoid function\n",
    "# A1 = tf.nn.sigmoid(Z1)\n",
    "\n",
    "# ============================================================\n",
    "# labels\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9151273\n",
      "Test accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "# cost function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Z1)\n",
    ")\n",
    "\n",
    "# model training aim is minimize cost function by mini-batch gradient descent\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5)\\\n",
    "                     .minimize(cross_entropy)\n",
    "    \n",
    "# run the training - computational graph\n",
    "for _ in range(1000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "# Evaluate the Model\n",
    "correct_prediction = tf.equal(tf.argmax(Z1,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Train accuracy\n",
    "print(\"Train accuracy:\", accuracy.eval(feed_dict={x: mnist.train.images, y_: mnist.train.labels}))\n",
    "\n",
    "# Test accuracy\n",
    "print(\"Test accuracy:\", accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why ANN with Numpy can obtain accuracy 98%, but MLP with TF can't?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network\n",
    "**Restart kernel to continue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and prepapre environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hung/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-0ba0eeba5048>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions definition\n",
    "\n",
    "def weight_variable(shape):\n",
    "    # initiate weight matrix, size = shape\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # initiate bias vector, size = shape\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    # convolutional function\n",
    "    # input layer x\n",
    "    # kernel weight matrix X\n",
    "    # strides=[1, 1, 1, 1]: move 1 (first) step by bacth, \n",
    "    # 1 (second + third) step by feature map width & height\n",
    "    # 1 step by filters\n",
    "    # padding\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    # poolfunction\n",
    "    # input layer x\n",
    "    # kernel size & strides =[1, 2, 2, 1]: 1 along batch, 2&2: along width&height, 1 along filters\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "x  = tf.placeholder(tf.float32, [None, 784], name='x')\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "# image 28x28\n",
    "#-----------------------------------------------------\n",
    "\n",
    "# Convolutional layer 1\n",
    "W_conv1 = weight_variable([3, 3, 1, 8])\n",
    "b_conv1 = bias_variable([8])\n",
    "# feature map 28x28x8\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# feature map 14x14x8\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Convolutional layer 2\n",
    "W_conv2 = weight_variable([3, 3, 8, 16])\n",
    "b_conv2 = bias_variable([16])\n",
    "# feature map 14x14x16\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# feature map 7x7x16\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Fully connected layer 1, 128 units, 7x7x16 inputs\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 16, 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "keep_prob  = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Fully connected layer 2 (Output layer), 10 units, 128 inputs\n",
    "W_fc2 = weight_variable([128, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2, name='y')\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# label\n",
    "y_ = tf.placeholder(tf.float32, [None, 10],  name='y_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation functions\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "# Training algorithm\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hung/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 0.0975\n",
      "100 0.147\n",
      "200 0.3775\n",
      "300 0.5625\n",
      "400 0.6063\n",
      "500 0.6932\n",
      "600 0.7427\n",
      "700 0.7846\n",
      "800 0.8151\n",
      "900 0.84\n",
      "1000 0.8588\n",
      "1100 0.8669\n",
      "1200 0.8772\n",
      "1300 0.8821\n",
      "1400 0.886\n",
      "1500 0.8964\n",
      "1600 0.8973\n",
      "1700 0.903\n",
      "1800 0.9074\n",
      "1900 0.9126\n",
      "2000 0.9105\n"
     ]
    }
   ],
   "source": [
    "# Training steps\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    max_steps = 2000\n",
    "    for step in range(max_steps):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(32)\n",
    "        if (step % 100) == 0:\n",
    "            print(step, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: 0.5})\n",
    "    print(max_steps, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(max_steps, sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
