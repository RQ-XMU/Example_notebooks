{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building 3-layer neural network from numpy\n",
    "Letâ€™s start by importing some libraires required for creating our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np ## Fr numerical python\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every layer will have a forward pass and backpass implementation. let's create a mian class layer which can do a forward pass .*forward()* and backward pass .*backward()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    # A building block. Each layer is capable of performing two things:\n",
    "    # - process inpput to get output \n",
    "    # output = layer.forward(input)\n",
    "    \n",
    "    # - propagate gradients through itself:\n",
    "    # grad_input = layer.backward(input, gradoutput)\n",
    "    \n",
    "    # Some layers also have learnable parameters which they update \n",
    "    # during layer.backward.\n",
    "    \n",
    "    def __init__(self):\n",
    "        # here we can initialize layer parameters (if any) \n",
    "        # and auxiliary stuff\n",
    "        # A dummy layer does nothing\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        # Takes input data of shape [batch, input_units], \n",
    "        #return ouput data [batch, output_units]\n",
    "        \n",
    "        # A dummy layer just returns whatever it gets as input.\n",
    "        return input_\n",
    "    \n",
    "    def backward(self, input_, grad_output):\n",
    "        # Performs a backpropagation step through the layer, \n",
    "        # with respect to the given input.\n",
    "        # To compute loss gradients w.r.t input, we need to apply \n",
    "        # chain rule (backprop):\n",
    "        # d_loss/d_x = (d_loss/d_layer) * (d_layer/d_x)\n",
    "        # luckily, we already receive d_loss/d_layer as input, \n",
    "        # so you only need to multiply it by d_layere/d_x.\n",
    "        # If our layer has parameters (e.g. dense layer), \n",
    "        # we also need to update them here using d_loss/d_layer\n",
    "        # Thegradient of dummy layer is precisely grad_output, \n",
    "        # but we'll write it more explicity\n",
    "        num_units = input_.shape[1]\n",
    "        d_layer_d_input = np.eye(num_units)\n",
    "        return np.dot(grad_output, d_layer_d_input) # chain rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinearity ReLU layer\n",
    "This is the simplest layer you can get: it simply applies a nonlinarity to each element of your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # ReLu layer simply applies elementwise rectified linear unit \n",
    "        # to all inputs\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        # Apply elementwise ReLU to [batch, input_units] matrix\n",
    "        relu_forward = np.maximum(0, input_)\n",
    "        return relu_forward\n",
    "    \n",
    "    def backward(self, input_, grad_output):\n",
    "        # Compute gradient of loss w.r.t ReLU input\n",
    "        relu_grad = input_ > 0\n",
    "        return grad_output*relu_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense layer\n",
    "Now let's build somethign more complicate. Unlike nonlinearity, a dense layer actully has something to learn. <br>\n",
    "A dense layer applies affine transformation. in a vectorized form, it can be described as:\n",
    "$$f(\\mathbf{X}) = \\mathbf{W} . \\mathbf{X} + \\mathbf{b}$$\n",
    "Where:<br>\n",
    "- $\\mathbf{X}$ is an object-feature matrix of shape [batch_size, num_features], <br>\n",
    "- $\\mathbf{W}$ is a weight matrix [num_features, num_outputs]<br>\n",
    "- and $\\mathbf{b}$ is a vector of num_outputs biases.\n",
    "\n",
    "\n",
    "Both $\\mathbf{W}$ and $\\mathbf{b}$ are initialized during layer creation and updated each time backward is called. Note that we are using **Xavier initialization** which is a trick to train our model to converge faster. Instead of initializing our weights with small numbers which are distributed randomly, we initialize our weights with mean zero and variance of 2/(number of inputs + number of outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "In case of multilayer perceptron with L layers\n",
    "\n",
    "$$ A_0 = X$$\n",
    "\n",
    "\n",
    "$$Z_1 = W_1.A_0 + B_1\\\\\n",
    "A_1 = g_1(Z_1)$$\n",
    "\n",
    "\n",
    "$$Z_2 = W_2.A_1 + B_2\\\\\n",
    "A_2 = g_2(Z_2)\\\\ ...$$\n",
    "\n",
    "$$Z_{L-1} = W_{L-1}.A_{L-2} + B_{L-1}\\\\\n",
    "A_{L-1} = g_{L-1}(Z_{L-1})$$\n",
    "\n",
    "\n",
    "$$Z_L = W_L.A{L_1} + B_L\\\\\n",
    "A_L = g_L(Z_L) = \\hat{Y}$$\n",
    "\n",
    "where at each layer $l,\\ l = 1,...,L$, there exists\n",
    "- $Z_l$: linear summator at $l$ layer\n",
    "- $A_l$: activator at $l$ layer\n",
    "- $B_l$: bias vector \n",
    "- $W_l$: weight matrix\n",
    "- $g_l$: activator function\n",
    "- input = $A_{l-1}$, output = $A_l$\n",
    "\n",
    "Then according to backpropagation:\n",
    "\n",
    "$$\\sigma = \\hat{Y} - Y = A_L - Y$$\n",
    "**grad_weights** = $\\displaystyle \\frac{\\partial \\sigma}{\\partial W_L} = \\frac{\\partial \\sigma}{\\partial A_L}\\frac{\\partial A_L}{\\partial Z_L}\\frac{\\partial Z_L}{\\partial W_L}$<br>\n",
    "**grad_output** = $\\displaystyle\\frac{\\partial \\sigma}{\\partial A_L}\\frac{\\partial A_L}{\\partial Z_L}$<br>\n",
    "**input** = $\\displaystyle\\frac{\\partial Z_L}{\\partial W_L} = A_{L-1}$<br>\n",
    "so: **grad_weights** = **grad_output** * **input**\n",
    "\n",
    "**grad_biases** = $\\displaystyle \\frac{\\partial \\sigma}{\\partial W_L} = \\frac{\\partial \\sigma}{\\partial A_L}\\frac{\\partial A_L}{\\partial Z_L}\\frac{\\partial Z_L}{\\partial B_L}$ = **grad_output** * $\\mathbb{1}$\n",
    "\n",
    "**grad_input** = $\\displaystyle\\frac{\\partial \\sigma}{\\partial A_{L-1}} = \\frac{\\partial \\sigma}{\\partial A_L}\\frac{\\partial A_L}{\\partial Z_L}\\frac{\\partial Z_L}{\\partial A_{L-1}}$ = **grad_output** * $\\displaystyle\\frac{\\partial Z_L}{\\partial A_{L-1}}$ = **grad_output** * $\\displaystyle W_L$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    \n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
    "        # A dense layer is a layer which performs a learned affine \n",
    "        # transformation:\n",
    "        # f(X) = W*X + b\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.normal(\n",
    "            loc=0.0, \n",
    "            scale=np.sqrt(2/(input_units+output_units)),\n",
    "            size=(input_units, output_units)\n",
    "        )\n",
    "        self.biases = np.zeros(output_units)\n",
    "    \n",
    "    def forward(self, input_):\n",
    "        # perform an affine transformation:\n",
    "        # f(X) = W*X + b\n",
    "        \n",
    "        # input shape: [batch, input_units]\n",
    "        # output shape: [batch, output_units]\n",
    "        \n",
    "        return np.dot(input_, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, input_, grad_output):\n",
    "        # compute d_f/d_x = d_f/d_dense * d_dense/d_x\n",
    "        # where d_dense/d_x = weights transposed\n",
    "        # and d_f/d_dense = grad_output\n",
    "        \n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        \n",
    "        # compute gradient w.r.t. weights and bias (things to update)\n",
    "        grad_weights = np.dot(input_.T, grad_output)\n",
    "        grad_biases = grad_output.mean(axis=0)*input_.shape[0]\n",
    "        \n",
    "        assert grad_weights.shape == self.weights.shape\\\n",
    "               and grad_biases.shape == self.biases.shape\n",
    "        \n",
    "        # Here we perform a schochastic gradient descent step.\n",
    "        self.weights = self.weights - self.learning_rate * grad_weights\n",
    "        self.biases = self.biases - self.learning_rate * grad_biases\n",
    "        \n",
    "        return grad_input     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The loss function\n",
    "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
    "\n",
    "If we write down the expression for crossentropy as a function of softmax logits(a), you'll see:\n",
    "$$loss = -\\log\\frac{e^{\\alpha_{\\text{correct}}}}{\\sum_i{e^{\\alpha_i}}}$$\n",
    "If we take a closer look, we'll see that it can be written as:\n",
    "$$loss = -\\alpha_{\\text{correct}}+\\log\\sum_i{e^{\\alpha_i}}$$\n",
    "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
    "\n",
    "- Better numerical stability\n",
    "- Easier to get derivative rigt\n",
    "- Marginally faster to compute\n",
    "\n",
    "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits, reference_answers):\n",
    "    # compute crossentropy from logits, sized [batch, n_classes] \n",
    "    # and ids of correct answers\n",
    "    \n",
    "    logits_for_answers = \\\n",
    "            logits[np.arange(len(logits)), reference_answers]\n",
    "    \n",
    "    xentropy = - logits_for_answers + \\\n",
    "                 np.log(np.sum(np.exp(logits), axis=-1))\n",
    "    \n",
    "    return xentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial loss}{\\partial\\alpha_{\\text{correct}}} = -\\mathbb{1} + \\frac{\\partial}{\\partial\\alpha_{\\text{correct}}}\\log\\sum_i{e^{\\alpha_i}} = -\\mathbb{1}+\\frac{e^{\\alpha_{\\text{correct}}}}{\\sum_i{e^{\\alpha_i}}} = -\\mathbb{1} + softmax(\\boldsymbol{\\alpha})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_softmax_crossentropy_with_logits(logits, reference_answers):\n",
    "    # compute crossentropy gradient from logits[batch, n_classes]\n",
    "    # and ids of correct answers\n",
    "    \n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)), reference_answers] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1, \n",
    "                                                  keepdims=True)\n",
    "    return (-ones_for_answers + softmax) / logits.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full network\n",
    "Now let's combine what we've just built into a working neural network. As I have told earlier, we are going to use MNIST data of handwritten digit for our example. Fortunately, Keras have it in the Numpy array format, so let's import it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# keras is only used for loading data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_dataset(flatten=False):\n",
    "        \n",
    "    # loading\n",
    "    (X_train, y_train), (X_test, y_test) = \\\n",
    "        keras.datasets.mnist.load_data()\n",
    "    \n",
    "    # each matrix of X is a array 28 x 28, each matrix element is\n",
    "    # a numbeer in [1...255], indicating bright intensity\n",
    "    # 0 = black, 255 = white, others = gray\n",
    "    \n",
    "    # each element of y is a class in [0...9]\n",
    "    \n",
    "    \n",
    "    # normalising\n",
    "    X_train = X_train.astype(float)/255.\n",
    "    X_test = X_test.astype(float)/255.\n",
    "    \n",
    "    # we reserve the last 10.000 training examples for validation\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "    \n",
    "    if flatten:\n",
    "        # transform size batch x 28 x 28 to batch x 724\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 55s 5us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc68033b630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data (need to dowload )\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = \\\n",
    "    load_dataset(flatten=True)\n",
    "# Look at some examples\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28,28]), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define network as a list of laysers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = []\n",
    "# fisrt hidden layer, dense, 724 inputs, 100 units, 100 outputs\n",
    "# no active function\n",
    "network.append(Dense(X_train.shape[1], 100))\n",
    "# active layer\n",
    "network.append(ReLU())\n",
    "# second hidden layer, 100 inputs, 200 units, 200 outputs\n",
    "network.append(Dense(100, 200))\n",
    "# active layer\n",
    "network.append(ReLU())\n",
    "# output layer, 200 inputs, 10 units, 10 outputs\n",
    "network.append(Dense(200, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Dense at 0x7fc680093860>,\n",
       " <__main__.ReLU at 0x7fc6800937f0>,\n",
       " <__main__.Dense at 0x7fc680093710>,\n",
       " <__main__.ReLU at 0x7fc680093630>,\n",
       " <__main__.Dense at 0x7fc6800935c0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(network, X):\n",
    "    # compute activations for all network layers \n",
    "    # by applying them sequentially.\n",
    "    # X: beginning in put\n",
    "    # Return a list of activations for each layers.\n",
    "        \n",
    "    activations = []\n",
    "    input_ = X\n",
    "    \n",
    "    # looping through each layer\n",
    "    for layer in network:\n",
    "        activations.append(layer.forward(input_))\n",
    "        # updating input to last layer output\n",
    "        input_ = activations[-1]\n",
    "        \n",
    "    assert len(activations) == len(network)\n",
    "    \n",
    "    return activations\n",
    "\n",
    "def predict(network, X):\n",
    "    # compute network predicstions.\n",
    "    # X: beginning in put\n",
    "    # Return indices of largest logit probability\n",
    "    \n",
    "    logits = forward(network, X)[-1]\n",
    "    return logits.argmax(axis=-1)\n",
    "\n",
    "def train(network, X, y):\n",
    "    # Train our network on a given batch of X and y.\n",
    "    # We first need to run forward to get all layer activations\n",
    "    # Then we can run layer.backward going from last to first layer.\n",
    "    # After we have called backward for all layers, all Dense layers \n",
    "    # have already made one gradient step\n",
    "    \n",
    "    # Get the layer activations\n",
    "    layer_activations = forward(network, X)\n",
    "    \n",
    "    # layer_input[i] is an input for network[i]\n",
    "    layer_inputs = [X] + layer_activations\n",
    "    \n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    # compute the loss and the initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits, y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits, y)\n",
    "    \n",
    "    # propagate gradients through the network\n",
    "    # reverse propagation as this is backprop\n",
    "    for layer_index in range(len(network))[::-1]:\n",
    "        layer = network[layer_index]\n",
    "        \n",
    "        # grad w.r.t. input, also weight updates\n",
    "        loss_grad = layer.backward(layer_inputs[layer_index], loss_grad)\n",
    "        \n",
    "    return np.mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop\n",
    "\n",
    "We split data into binibatches, feed each such minibatch into the network and update weights. This training is called mini-batch stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs)-batchsize+1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx+batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx+batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train accuracy 1.0\n",
      "Validation accuracy 0.9808\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc658a9f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to reset network before launching this cell\n",
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for x_batch, y_batch in \\\n",
    "        iterate_minibatches(\n",
    "            inputs=X_train, \n",
    "            targets=y_train,\n",
    "            batchsize=32,\n",
    "            shuffle=True\n",
    "        ):\n",
    "        train(network, x_batch, y_batch)\n",
    "        \n",
    "    train_log.append(np.mean(predict(network, X_train)==y_train))\n",
    "    val_log.append(np.mean(predict(network, X_val)==y_val))\n",
    "        \n",
    "    clear_output()\n",
    "    print(\"Epoch\", epoch)\n",
    "    print(\"Train accuracy\", train_log[-1])\n",
    "    print(\"Validation accuracy\", val_log[-1])\n",
    "    \n",
    "    plt.plot(train_log, label='train accuracy')\n",
    "    plt.plot(val_log, label='validation accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we have successfully train a MLP which was purely written in Numpy with high validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9837"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "np.mean(predict(network, X_test)==y_test)\n",
    "# on 35 epoches is 0.9837"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 8 \n",
      "Sample:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6583c0518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test model\n",
    "xtest = X_test[-100].reshape([1,784])\n",
    "plt.imshow(xtest[0].reshape([28,28]), cmap='gray')\n",
    "print(\"Prediction:\", predict(network, xtest)[0], \"\\nSample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 247, 321, 340, 445, 449, 495, 582, 684, 720, 740, 877, 900, 947, 951, 1014, 1039, 1044, 1112, 1178, 1181, 1194, 1224, 1226, 1247, 1319, 1328, 1393, 1395, 1414, 1494, 1500, 1530, 1671, 1681, 1717, 1790, 1850, 1878, 1901, 1952, 1984, 1987, 2018, 2035, 2053, 2070, 2098, 2109, 2118, 2130, 2135, 2272, 2293, 2387, 2414, 2447, 2488, 2607, 2648, 2654, 2810, 2877, 2896, 2915, 2921, 2939, 2995, 3073, 3117, 3225, 3251, 3422, 3441, 3474, 3490, 3503, 3520, 3549, 3558, 3681, 3776, 3796, 3808, 3893, 3906, 3941, 4065, 4078, 4123, 4140, 4163, 4176, 4199, 4201, 4248, 4300, 4344, 4425, 4497, 4536, 4551, 4567, 4601, 4671, 4731, 4740, 4751, 4807, 4823, 4860, 4876, 4880, 4966, 5046, 5457, 5600, 5642, 5676, 5734, 5936, 5937, 5955, 5972, 5973, 5997, 6023, 6059, 6166, 6555, 6559, 6560, 6574, 6597, 6625, 6755, 6783, 6926, 7216, 7434, 8062, 8094, 8246, 8255, 8273, 8311, 8325, 8339, 8527, 9009, 9015, 9024, 9587, 9634, 9664, 9669, 9679, 9729, 9745, 9749, 9755, 9768, 9770, 9839, 9858, 9944]\n"
     ]
    }
   ],
   "source": [
    "# fail in test\n",
    "indices = []\n",
    "for i in range(0,len(X_test)):\n",
    "    xtest = X_test[i].reshape([1,784])\n",
    "    label = y_test[i]\n",
    "    pred = predict(network, xtest)[0]\n",
    "    if  pred != label:\n",
    "        indices.append(i)\n",
    "print(indices)\n",
    "#         plt.imshow(xtest[0].reshape([28,28]), cmap='gray')\n",
    "#         print(\"Index:\",i,\"\\nLabel:\", label, \"\\nPrediction:\", pred, \"\\nSample:\")\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_test)-len(indices))/float(len(X_test)) # 30 epoches is 0.9834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
