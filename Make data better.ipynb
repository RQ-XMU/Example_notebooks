{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing your dataset for Machine Learning: 8 basic techniques that make your data better\n",
    "\n",
    "There's a good story about bad data told by [Martin Goodson](http://www.martingoodson.com/author/martin/), a data science consultatn. A healthcare project was aimed to cut costs in the treatment of patients with pneumonia. It employed machine learning to automatically sort through patient records to decide who has the lowest death risk and should take antibiotics at home and who is at a high risk of death from pneumonia and should be in the hospital. The team used historic data from clinics, and the algorithm was accurate.\n",
    "\n",
    "But there was with an important exception. One of the most dangerous conditions that may accompany pneumonia is asthma, and doctors always send asthmatics to intensive care resulting in minimal death rates for these patients. So, the absence of asthmatic death cases in the data made the algorithm assume that asthma ins't that dangerous during pneumonia, and in all cases the machine recommended sending asthmatics home, while they had the highest rissk of pneumonia complications.\n",
    "\n",
    "ML depends heavily on data. It's the most crucial aspect that makes algorithm training possible and explains why machine learning became so popular in recent years. But regardless for your actual terabytes of information and data science expertise, if you can't make sense of data records, a machine will be nearly useless or perhaps even harmful.\n",
    "\n",
    "The thing is, all datasets are flawed. That why data preparation is such an important step in the machine learning process. In a nutshell, data preparation is a set of precedures that helps make you dataset more suitable for machine learning. In broader terms, the preparation also includes establishing the right data collection mechanism. And these procedures consume most of the time spent on machine learning. Sometimes its takes months before the first algorithm is built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation is sometimes a DIY project\n",
    "If you were to consider a spherical machine-learning cow, all data preparation should be done by a dedicated data scientist. And that's about right. If you don't have a data scientist on board to do all the cleaning, well ... you don't have machine learning. But as we discussed in our story on data science team structures, life is hard for companies that cna't afford data science talent and try to transition existing IT engineers into the field. Bedides, dataset perparations isn't narrowed down to a data scientist's compentencies only. Problems with datasets can stem from the way an organization is built, workflows that are enstablished, and wether instructions are adhered to or not among those charged with recordkeeping.\n",
    "\n",
    "Yes, you can rely completely on a data scientist in dataset preparation, but by tknowing some techniques in advance there's away to meaningfully lighten the load of the person who's going to face this Herculean task. \n",
    "\n",
    "So, let's have a look at the most common dataset problems and the ways to solve them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You don't have data\n",
    "\n",
    "The line dividing those who cna play with ML and those who can't is drawn by years of collecting information. Some organizations have beens hoarding recoreds for decades with such great success that now they need trucks to move it to the cloud as conventional broadband is just not borad enough.\n",
    "\n",
    "For those who've just come on the scene, lack of data is expected, but fortunately, there are ways to turn that minus into a plus.\n",
    "\n",
    "First, rely on open source data to initiate ML execution. There are mountains of data around and some companies (like Google) are ready to give it away. We'll talk about public dataset opportunites a bit later. While those opporunities exist, usually the real value comes form internally collected golden data nuggets mined from the business decisions and activities of your own company.\n",
    "\n",
    "Second--and not surprisingly--now you have a chance to collect data the right way. The companies that started data collection with paper ledgers and ended with .xlsx and .csv files will likely have a harder time with data prepartion than those who have a small but proud ML-friendly dataset. If you know the tasks that machine learning should solve, you can tailor a data gathering mechanism in advance.\n",
    "\n",
    "What about big data? It's so buzzed, it seems like thing everyone should be doing. Aiming st big data from the start is a good mindset, but big data isn't about petabytes. It's all about the ability to process them the right way. The larger your dataset, the harder it gets to make the right use of it and yiels insights. having tons of lumber doesn't necessarily mean you can convert it to a warehouse full of chairs and tables. So, the generla recommendation for beginners is to start small and reduce the complexity of their data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Articulate the problem early\n",
    "\n",
    "Knowing what you want to predict will help you decide which data may be more valuable to collect. When formulating the problem, try to think in the categories of classification, clustering, regression, and ranking that we talked about in our whitepaper on business application of machine learning. In layman's terms, these tasks are differentiated in the following way:\n",
    "\n",
    "**Classification**: You want an algorithm to answer binary yes-or-no questions (cats or dogs, good or bas, sheeps or goats, you get the idea) or you want to make a multiclass classification (grass, trees, or bushes; cats, dogs, or birds etc.) You also need the right answers lebeled, so an algorithm can learn from them. \n",
    "\n",
    "**Clustering**. You want an algorithm to find the rules of classification and the number of classes. The main difference from classification tasks is that you don't actually know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
