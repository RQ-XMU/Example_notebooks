{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book realizes adaptive fuzzy neural network with Numpy\n",
    "\n",
    "The architecture of AFNN as folow:\n",
    "![](https://www.researchgate.net/profile/Ahmed_Hafaifa/publication/305519718/figure/fig4/AS:391662376374286@1470390995677/Adaptive-fuzzy-neural-network-with-inference-system.png)\n",
    "\n",
    "where:\n",
    "- layer 1: **Fuzzification layer**: $A_{ij} \\rightarrow \\mu_{ij}(x_i=A_{ij})$\n",
    "- layer 2: **Rule operation layer**: $\\displaystyle \\Pi_r = \\prod_{i=1,\\ x_i=A_{ij}}^{m}\\mu_{ij}(x_i=A_{ij})$\n",
    "- layer 3: **Normalization layer**: $\\displaystyle \\overline{w}_r = \\frac{w_r}{\\sum_{r'}w_{r'}}$\n",
    "- layer 4: **Consequent layer**: $c_r = \\overline{w}_rf_r$\n",
    "- layer 5: **Aggregation layer**: $\\hat{y}=\\sum_{r}\\overline{w}_rf_r$\n",
    "- All $f_r$ are found by minimum objective function based on true values ($y_k$) and predicted values ($\\hat{y}_k$)\n",
    "- Finally rules can be expressed as:\n",
    "$$\n",
    "\\mathbf{If\\ } x_1 = A_{11} \\mathbf{\\ and\\ } x_1 = A_{21} \\mathbf{\\ and...\\ then\\ } y=f_1 \\text{ and so on ...}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership functions Definition\n",
    "### Gaussian fuzzy membership function\n",
    "$$\n",
    "\\mu_{\\mu, \\sigma}(x)=\\exp \\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "#### Derivatives\n",
    "$$\n",
    "\\frac{\\partial \\mu_{\\mu, \\sigma}(x)}{\\partial x} = \\mu_{\\mu, \\sigma}(x)\\cdot\\frac{\\mu-x}{\\sigma^2}\\\\\n",
    "\\frac{\\partial \\mu_{\\mu, \\sigma}(x)}{\\partial \\mu} = \\mu_{\\mu, \\sigma}(x)\\cdot\\frac{x-\\mu}{\\sigma^2}\\\\\n",
    "\\frac{\\partial \\mu_{\\mu, \\sigma}(x)}{\\partial \\sigma} = \\mu_{\\mu, \\sigma}(x)\\frac{(x-\\mu)^2}{\\sigma^3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Bell membership function \n",
    "$$\n",
    "\\displaystyle \\mu_{a,b,c}(x) = \\frac{1}{1+\\left|\\frac{x-c}{a}\\right|^{2b}}\n",
    "$$\n",
    "#### Derivatives\n",
    "$$\n",
    "\\frac{\\partial \\mu_{a,b,c}(x)}{\\partial x} = -\\frac{1}{\\mu_{a,b,c}^2(x)}\\left|\\frac{x-c}{a}\\right|^{2b-2}\\frac{2b(c-x)}{a^2}\\\\\n",
    "\\frac{\\partial \\mu_{a,b,c}(x)}{\\partial c} = -\\frac{1}{\\mu_{a,b,c}^2(x)}\\left|\\frac{x-c}{a}\\right|^{2b-2}\\frac{2b(c-x)}{a^2}\\\\\n",
    "\\frac{\\partial \\mu_{a,b,c}(x)}{\\partial a} = -\\frac{1}{\\mu_{a,b,c}^2(x)}\\left|\\frac{x-c}{a}\\right|^{2b}\\frac{2b}{a}\\\\\n",
    "\\frac{\\partial \\mu_{a,b,c}(x)}{\\partial b} = -\\frac{1}{\\mu_{a,b,c}^2(x)}\\left|\\frac{x-c}{a}\\right|^{2b}\\cdot 2\\ln\\left|\\frac{x-c}{a}\\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized sigmoid membership function \n",
    "$$\n",
    "\\mu_{b,c}(x) = \\frac{1}{1+e^{-c(x-b)}}\n",
    "$$\n",
    "#### Derivatives\n",
    "$$\n",
    "\\frac{\\partial \\mu_{b,c}(x)}{\\partial x} = \\frac{c\\cdot e^{-c(x-b)}}{\\mu^2_{b,c}(x)}\\\\\n",
    "\\frac{\\partial \\mu_{b,c}(x)}{\\partial b} = \\frac{-c \\cdot e^{-c(x-b)}}{\\mu^2_{b,c}(x)}\\\\\n",
    "\\frac{\\partial \\mu_{b,c}(x)}{\\partial c} = \\frac{(x-b)\\cdot e^{-c(x-b)}}{\\mu^2_{b,c}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership functions Implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussmf(x, mean, sigma):\n",
    "    \"\"\"\n",
    "    Gaussian fuzzy membership function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1d array or iterable\n",
    "        Independent variable.\n",
    "    mean : float\n",
    "        Gaussian parameter for center (mean) value.\n",
    "    sigma : float\n",
    "        Gaussian parameter for standard deviation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : 1d array\n",
    "        Gaussian membership function for x.\n",
    "    \"\"\"\n",
    "    return np.exp(-((x - mean)**2.) / (2 * sigma**2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbellmf(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Generalized Bell function fuzzy membership generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1d array\n",
    "        Independent variable.\n",
    "    a : float\n",
    "        Bell function parameter controlling width. See Note for definition.\n",
    "    b : float\n",
    "        Bell function parameter controlling slope. See Note for definition.\n",
    "    c : float\n",
    "        Bell function parameter defining the center. See Note for definition.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : 1d array\n",
    "        Generalized Bell fuzzy membership function.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Definition of Generalized Bell function is:\n",
    "\n",
    "        y(x) = 1 / (1 + abs([x - c] / a) ** [2 * b])\n",
    "    \"\"\"\n",
    "    return 1. / (1. + np.abs((x - c) / a) ** (2 * b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmf(x, b, c):\n",
    "    \"\"\"\n",
    "    The basic sigmoid membership function generator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 1d array\n",
    "        Data vector for independent variable.\n",
    "    b : float\n",
    "        Offset or bias.  This is the center value of the sigmoid, where it\n",
    "        equals 1/2.\n",
    "    c : float\n",
    "        Controls 'width' of the sigmoidal region about `b` (magnitude); also\n",
    "        which side of the function is open (sign). A positive value of `a`\n",
    "        means the left side approaches 0.0 while the right side approaches 1.;\n",
    "        a negative value of `c` means the opposite.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : 1d array\n",
    "        Generated sigmoid values, defined as y = 1 / (1. + exp[- c * (x - b)])\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    These are the same values, provided separately and in the opposite order\n",
    "    compared to the publicly available MathWorks' Fuzzy Logic Toolbox\n",
    "    documentation. Pay close attention to above docstring!\n",
    "    \"\"\"\n",
    "    return 1. / (1. + np.exp(- c * (x - b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f282c057908>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f282c131390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(range(-500, 501))/100\n",
    "gau = gaussmf(x=x, mean=-0.5, sigma=1)\n",
    "bell = gbellmf(x=x, a=1, b=2, c=1)\n",
    "sig = sigmf(x=x, b=2, c=3)\n",
    "\n",
    "plt.plot(x, gau, 'r', label='Gaussian')\n",
    "plt.plot(x, bell, 'g', label='Bell')\n",
    "plt.plot(x, sig, 'b', label='Sigmoid')\n",
    "plt.title('Membership function graph')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership function class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemFuncs:\n",
    "    \"\"\"Common base class for all employees\"\"\"\n",
    "    \n",
    "    funcDict = {'gaussmf': gaussmf, 'gbellmf': gbellmf, 'sigmf': sigmf}\n",
    "\n",
    "    def __init__(self, MFList):\n",
    "        \"\"\"\n",
    "        Initialise\n",
    "        MFList structure\n",
    "        MFList = [ListMF0, ListMF1, ...]\n",
    "        ListMF = [MF0, MF1, ...]\n",
    "        MF = ['membership_function_name', {'membership_function_parameter': values, ...}]\n",
    "        \n",
    "        See the example below for more detail\n",
    "        \n",
    "        Number of ListMF = input dimmesion = m in the graph at the beginning\n",
    "        Number of MF can be the same for all variable (homogenous) or different for each\n",
    "        It is recommend to set these number are the same to work with Numpy\n",
    "        \"\"\"\n",
    "        self.MFList = MFList\n",
    "\n",
    "    def evaluateMF(self, rowInput):\n",
    "        \"\"\"\n",
    "        Evaluate membership function from rowInput\n",
    "        The code below use i to index MFList for i-th row\n",
    "        and k to index MFs for a specified row in rowInput\n",
    "        \n",
    "        len(rowInput) should be equal to number of MFList\n",
    "        If len(rowInput) > len(MFList) there will be warning and results\n",
    "        If len(rowInput) < len(MFList) there will be warning and \n",
    "        \"\"\"\n",
    "        \n",
    "        if len(rowInput) != len(self.MFList):\n",
    "            print(\"Number of variables does not match number of rule sets\")\n",
    "            \n",
    "        return np.array([\n",
    "            [\n",
    "                self.funcDict[\n",
    "                    self.MFList[i][k][0]\n",
    "                ](rowInput[i],**self.MFList[i][k][1]) \n",
    "                for k in range(len(self.MFList[i]))\n",
    "            ] \n",
    "            for i in range(len(rowInput))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array([1.35335283e-01, 1.11089965e-02, 3.35462628e-04, 3.72665317e-06]),\n",
       "        array([0.32465247, 0.13533528, 0.04393693, 0.011109  ]),\n",
       "        array([0.83527021, 0.78270454, 0.72614904, 0.66697681]),\n",
       "        array([0.43756474, 0.36044779, 0.29092381, 0.2300663 ])],\n",
       "       [array([0.60653066, 0.32465247, 0.13533528]),\n",
       "        array([0.94595947, 0.8007374 , 0.60653066]),\n",
       "        array([0.8824969 , 0.83527021, 0.78270454]),\n",
       "        array([0.02612141, 0.01492079, 0.0081887 ])]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MFList = [\n",
    "    [\n",
    "        ['gaussmf', {'mean':0.,'sigma':1.}],\n",
    "        ['gaussmf', {'mean':-1.,'sigma':2.}],\n",
    "        ['gaussmf', {'mean':-4.,'sigma':10.}],\n",
    "        ['gaussmf', {'mean':-7.,'sigma':7.}]\n",
    "    ],\n",
    "    [\n",
    "        ['gaussmf', {'mean':1.,'sigma':2.}],\n",
    "        ['gaussmf', {'mean':2.,'sigma':3.}],\n",
    "        ['gaussmf', {'mean':-2.,'sigma':10.}],\n",
    "        ['gaussmf', {'mean':-10.5,'sigma':5.}]\n",
    "    ]\n",
    "]\n",
    "\n",
    "mfca = MemFuncs(MFList)\n",
    "var_test = np.array([np.array([2, 3, 4, 5]),\n",
    "                     np.array([3, 4, 5])])\n",
    "\n",
    "mfca.evaluateMF(var_test)\n",
    "# There must be array of two arrays\n",
    "# first with (4,4) shape\n",
    "# second for (4,3) shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membership function derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgaussmfMean(x, mean, sigma):\n",
    "    \"\"\"\n",
    "    Derivative gaussian membership function by mean\n",
    "    np.exp(-((x - mean)**2.) / (2 * sigma**2.))\n",
    "    \"\"\"\n",
    "    return (1./sigma**2) *(x-mean) * gaussmf(x, mean, sigma)\n",
    " \n",
    "\n",
    "def dgaussmfSigma(x, mean, sigma):\n",
    "    \"\"\"\n",
    "    Derivative gaussian membership function by sigma\n",
    "    \"\"\"\n",
    "    return (1./sigma**3) * (x-mean)**2 * gaussmf(x, mean, sigma)\n",
    "\n",
    "\n",
    "def dgbellmfA(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Derivative bell membership function by a\n",
    "    \"\"\"\n",
    "    return gbellmf(x,a,b,c)*(1-gbellmf(x,a,b,c))*2.*b/a\n",
    "\n",
    "\n",
    "def dgbellmfB(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Derivative bell membership function by b\n",
    "    \"\"\"\n",
    "    return -2*gbellmf(x, a, b, c)*(1-gbellmf(x, a, b, c))*np.log(np.abs((x-c)/a)) \n",
    "                \n",
    "\n",
    "def dgbellmfC(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Derivative bell membership function by c\n",
    "    \"\"\"\n",
    "    return -2.*b/(c-x) * gbellmf(x, a, b, c)*(1-gbellmf(x, a, b, c))\n",
    "\n",
    "\n",
    "def dsigmfB(x, b, c):\n",
    "    \"\"\"\n",
    "    Derivative sigmoid membership function by b\n",
    "    1. / (1. + np.exp(- c * (x - b)))\n",
    "    \n",
    "    \"\"\"\n",
    "    return -c * (1-sigmf(x, b, c)) * sigmf(x, b, c)\n",
    "    \n",
    "    \n",
    "def dsigmfC(x, b, c):\n",
    "    \"\"\"\n",
    "    Derivative sigmoid membership function by c\n",
    "    \"\"\"\n",
    "    return (x - b) * (1-sigmf(x, b, c)) * sigmf(x, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_dMF(x, mf_definition, partial_parameter):\n",
    "    \"\"\"\n",
    "    Calculates the partial derivative of a membership function at a point x.\n",
    "    This is for back-propagation over parameter\n",
    "    Parameters\n",
    "    x: input variable\n",
    "    mf_definition: membership funtion definition, \n",
    "    e.g.: ['gaussmf', {'mean':0.,'sigma':1.}]\n",
    "    partial_parameter: parameter to gte derivative\n",
    "    ------\n",
    "    Returns\n",
    "    derivative of membership function by parameter\n",
    "    ------\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    # get function name\n",
    "    mf_name = mf_definition[0]\n",
    "    \n",
    "    # Gaussian membership function derivatives\n",
    "    if mf_name == 'gaussmf':\n",
    "        # get parameters\n",
    "        sigma = mf_definition[1]['sigma']\n",
    "        mean = mf_definition[1]['mean']\n",
    "        # calculate derivatives\n",
    "        if partial_parameter == 'sigma':   # dMf/dSigma\n",
    "            result = dgaussmfSigma(x, mean, sigma)\n",
    "        elif partial_parameter == 'mean':  # dMf/dMean\n",
    "            result = dgaussmfMean(x, mean, sigma)\n",
    "    \n",
    "    # Bell membership function derivatives\n",
    "    elif mf_name == 'gbellmf':\n",
    "        # get parameters\n",
    "        a = mf_definition[1]['a']\n",
    "        b = mf_definition[1]['b']\n",
    "        c = mf_definition[1]['c']\n",
    "        # calculate derivatives\n",
    "        if partial_parameter == 'a':    # dMf/da\n",
    "            result = dgbellmfA(x, a, b, c)\n",
    "        elif partial_parameter == 'b':  # dMf/db\n",
    "            result = dgbellmfB(x, a, b, c)\n",
    "        elif partial_parameter == 'c':  # dMf/dc \n",
    "            result = dgbellmfC(x, a, b, c)\n",
    "    \n",
    "    # General sigmoid membership function derivatives\n",
    "    elif mf_name == 'sigmf':\n",
    "        # get parameters\n",
    "        b = mf_definition[1]['b']\n",
    "        c = mf_definition[1]['c']\n",
    "        # calculate derivatives\n",
    "        if partial_parameter == 'b':    # dMf/db\n",
    "            result = dsigmfB(x, b, c)\n",
    "        elif partial_parameter == 'c':  # dMf/dc\n",
    "            result = dsigmfC(x, b, c)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test derivatives\n",
    "Estimated\n",
    "$$\\widehat{\\frac{\\partial f(x)}{\\partial x}}=\\frac{f(x+\\epsilon)-f(x-\\epsilon)}{2\\epsilon}\\text{ where } \\epsilon \\approx 0\n",
    "$$\n",
    "#### Gausian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean's difference: -2.022388480016346e-07\n",
      "Sigma's difference: 3.608129017229622e-07\n"
     ]
    }
   ],
   "source": [
    "funDict = {'gaussmf': gaussmf, 'gbellmf': gbellmf, 'sigmf': sigmf}\n",
    "mfdef = ['gaussmf', {'mean':0.,'sigma':1.}]\n",
    "xtest = 0.5\n",
    "eps = 0.001\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['mean']+eps, mfdef[1]['sigma'])\\\n",
    "           -funDict[mfdef[0]](xtest, mfdef[1]['mean']-eps, mfdef[1]['sigma']))/(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'mean')\n",
    "\n",
    "print(\"Mean's difference:\", ets_der - ets_cal)\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['mean'], mfdef[1]['sigma']+eps)\\\n",
    "           -funDict[mfdef[0]](xtest, mfdef[1]['mean'], mfdef[1]['sigma']-eps))/(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'sigma')\n",
    "print(\"Sigma's difference:\", ets_der - ets_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bell function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a's difference: 2.0002207765656976e-06\n",
      "b's difference: -7.050712671347048e-07\n",
      "c's difference: 7.5819991969539036e-06\n"
     ]
    }
   ],
   "source": [
    "mfdef = ['gbellmf', {'a': -1.5,'b': 2, 'c': -2.}]\n",
    "xtest = 0.5\n",
    "eps = 0.01\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['a']+eps, mfdef[1]['b'], mfdef[1]['c']) - \\\n",
    "          funDict[mfdef[0]](xtest, mfdef[1]['a']-eps, mfdef[1]['b'], mfdef[1]['c']))\\\n",
    "          /(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'a')\n",
    "\n",
    "print(\"a's difference:\", ets_der - ets_cal)\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['a'], mfdef[1]['b']+eps, mfdef[1]['c']) - \\\n",
    "          funDict[mfdef[0]](xtest, mfdef[1]['a'], mfdef[1]['b']-eps, mfdef[1]['c']))\\\n",
    "          /(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'b')\n",
    "\n",
    "print(\"b's difference:\", ets_der - ets_cal)\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['a'], mfdef[1]['b'], mfdef[1]['c']+eps) - \\\n",
    "          funDict[mfdef[0]](xtest, mfdef[1]['a'], mfdef[1]['b'], mfdef[1]['c']-eps))\\\n",
    "          /(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'c')\n",
    "\n",
    "print(\"c's difference:\", ets_der - ets_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b's difference: 8.084596164747992e-08\n",
      "c's difference: 6.467923002739795e-10\n"
     ]
    }
   ],
   "source": [
    "mfdef = ['sigmf', {'b': 1, 'c': 2.}]\n",
    "xtest = 0.6\n",
    "eps = 0.001\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['b']+eps, mfdef[1]['c']) - \\\n",
    "          funDict[mfdef[0]](xtest, mfdef[1]['b']-eps, mfdef[1]['c']))\\\n",
    "          /(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'b')\n",
    "\n",
    "print(\"b's difference:\", ets_der - ets_cal)\n",
    "\n",
    "ets_der = (funDict[mfdef[0]](xtest, mfdef[1]['b'], mfdef[1]['c']+eps) - \\\n",
    "          funDict[mfdef[0]](xtest, mfdef[1]['b'], mfdef[1]['c']-eps))\\\n",
    "          /(2*eps)\n",
    "ets_cal = partial_dMF(xtest, mfdef, 'c')\n",
    "\n",
    "print(\"c's difference:\", ets_der - ets_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As differences are closed to 0, our derivative functions were correctly defined**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANFIS class implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSE(A, B, initialGamma = 1000.):\n",
    "    \"\"\"\n",
    "    Use least squared estimation to find LSE(A,B) that\n",
    "    A.dot(LSE(A, B)) ~ B\n",
    "    This function is used to fined coefficients between layer 4 & 5\n",
    "    where A.shape[0] = number of rules\n",
    "    if A.shape[0] is very big, this function will slowly execute\n",
    "    \"\"\"\n",
    "    \n",
    "    coeffMat = np.array(A)\n",
    "    rhsMat = np.array(B)\n",
    "\n",
    "    S = np.eye(coeffMat.shape[1])*initialGamma\n",
    "    x = np.zeros((coeffMat.shape[1], 1))\n",
    "    \n",
    "    for i in range(coeffMat.shape[0]):\n",
    "        a = np.matrix(coeffMat[i])\n",
    "        b = np.matrix(rhsMat[i])\n",
    "        S = S - S.dot(a.T).dot(a).dot(S)/(1+a.dot(S).dot(a.T))\n",
    "        x = x + S.dot(a.T).dot(b-a.dot(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is quite long!!!\n",
    "class ANFIS(object):\n",
    "    \"\"\"Class to implement an Adaptive Network Fuzzy Inference System: ANFIS\"\n",
    "\n",
    "    Attributes:\n",
    "        X - input\n",
    "        Y - output\n",
    "        XLen - input len\n",
    "        memClass - membership function object\n",
    "        memFuncs - membership function list\n",
    "        memFuncsByVariable - membership function by variable\n",
    "        \n",
    "        rules - fuzzy rules\n",
    "            if x1 gets value from [x11, x12]\n",
    "               x2 gets value from [x21, x22]\n",
    "            then rule 'x1 = x11 & x2 = x21' equivalent (0,0) and so on.  \n",
    "               \n",
    "        consequents - layerFour.dot(consequents) = layerFive\n",
    "        errors - sum square(real values - predicted values)\n",
    "        memFuncsHomo - true if there's the same number of membership functions \n",
    "        for all variables\n",
    "            example\n",
    "                if memFuncs = [[['gaussmf',...],['gaussmf', ...]],\n",
    "                               [['gaussmf', ...],['gaussmf', ...]]]\n",
    "                then memFuncsHomo = True (2 membership functions for each)\n",
    "        trainingType - 'Not trained yet'/'trainHybridJangOffLine'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, Y, memFunction):\n",
    "        \"\"\"\n",
    "        Initialise ANFIS instance from\n",
    "        - input X = [[val1, val2, ...], [...]]\n",
    "        - output Y [...]\n",
    "        - membership function object memFunction [see: class MemFuncs]\n",
    "        X.shape[0] - number of training sample\n",
    "        X.shape[1] - number of inputs in fuzzy neural net\n",
    "        \"\"\"\n",
    "        self.X = np.array(copy.copy(X))\n",
    "        self.Y = np.array(copy.copy(Y))\n",
    "        self.XLen = len(self.X)\n",
    "        \n",
    "        self.memClass = copy.deepcopy(memFunction)\n",
    "        self.memFuncs = self.memClass.MFList\n",
    "        \n",
    "        # indexing membership function \n",
    "        self.memFuncsByVariable = [\n",
    "            [x for x in range(len(self.memFuncs[z]))]\n",
    "            for z in range(len(self.memFuncs))\n",
    "        ]\n",
    "        \n",
    "        # list of possible rules = \n",
    "        # number of membership fuctions for 1st variable *\n",
    "        # number of membership fuctions for 2nd variable ...\n",
    "        self.rules = np.array(list(itertools.product(*self.memFuncsByVariable)))\n",
    "        \n",
    "        self.consequents = \\\n",
    "        np.zeros(self.Y.ndim * len(self.rules) * (self.X.shape[1] + 1))\n",
    "        self.errors = np.empty(0)\n",
    "        \n",
    "        self.memFuncsHomo = all(\n",
    "            len(i)==len(self.memFuncsByVariable[0]) \n",
    "            for i in self.memFuncsByVariable\n",
    "        )\n",
    "        \n",
    "        self.trainingType = 'Not trained yet'\n",
    "\n",
    "    def trainHybridJangOffLine(self, epochs=5, tolerance=1e-5, initialGamma=1000, k=0.01):\n",
    "        \"\"\"\n",
    "        Training fuzzy neural network (update parameters of membership functions)\n",
    "        epochs: number of epochs\n",
    "        tolerance: tolerance to stop updating parameters \n",
    "        initialGamma: used to find LSE(A, B)\n",
    "        k: learning rate\n",
    "        Return predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        self.trainingType = 'trainHybridJangOffLine'\n",
    "        convergence = False\n",
    "        epoch = 1\n",
    "\n",
    "        while (epoch <= epochs) and (convergence is not True):\n",
    "\n",
    "            #layer four: forward pass\n",
    "            [layerFour, wSum, w] = self.forwardHalfPass(self.X)\n",
    "\n",
    "            #layer five: least squares estimate\n",
    "            layerFive = np.array(LSE(layerFour,self.Y,initialGamma))\n",
    "            self.consequents = layerFive\n",
    "            \n",
    "            # layer five, final forward pass\n",
    "            layerFive = layerFour.dot(layerFive)\n",
    "\n",
    "            # error - RMSE\n",
    "            error = np.sum((self.Y-layerFive.T)**2)/self.Y.shape[0]\n",
    "            error = np.sqrt(error)\n",
    "            print('Epoch --%d/%d-- Train error --%.9f--' % (epoch, epochs, error))\n",
    "            # MAE\n",
    "            # average_error = np.average(np.absolute(self.Y-layerFive.T))\n",
    "            self.errors = np.append(self.errors,error)\n",
    "\n",
    "            if len(self.errors) != 0:\n",
    "                if self.errors[len(self.errors)-1] < tolerance:\n",
    "                    convergence = True\n",
    "\n",
    "            # back propagation\n",
    "            if convergence is not True:\n",
    "                cols = range(self.X.shape[1])\n",
    "                dE_dAlpha = list(self.backprop(colX, cols, wSum, w, layerFive) \n",
    "                                 for colX in range(self.X.shape[1]))\n",
    "\n",
    "\n",
    "            if len(self.errors) >= 4:\n",
    "                if (self.errors[-4] > self.errors[-3] > \\\n",
    "                    self.errors[-2] > self.errors[-1]):\n",
    "                    k = k * 1.1\n",
    "\n",
    "            if len(self.errors) >= 5:\n",
    "                if (self.errors[-1] < self.errors[-2]) \\\n",
    "                   and (self.errors[-3] < self.errors[-2]) \\\n",
    "                   and (self.errors[-3] < self.errors[-4]) \\\n",
    "                   and (self.errors[-5] > self.errors[-4]):\n",
    "                    k = k * 0.9\n",
    "\n",
    "            # handling of variables with a different number of MFs\n",
    "            t = []\n",
    "            for x in range(len(dE_dAlpha)):\n",
    "                for y in range(len(dE_dAlpha[x])):\n",
    "                    for z in range(len(dE_dAlpha[x][y])):\n",
    "                        t.append(dE_dAlpha[x][y][z])\n",
    "\n",
    "            eta = k / np.abs(np.sum(t))  # learning rate\n",
    "\n",
    "            if(np.isinf(eta)):\n",
    "                eta = k\n",
    "\n",
    "            ## handling of variables with a different number of MFs\n",
    "            dAlpha = copy.deepcopy(dE_dAlpha)\n",
    "            if not(self.memFuncsHomo):\n",
    "                for x in range(len(dE_dAlpha)):\n",
    "                    for y in range(len(dE_dAlpha[x])):\n",
    "                        for z in range(len(dE_dAlpha[x][y])):\n",
    "                            dAlpha[x][y][z] = -eta * dE_dAlpha[x][y][z]\n",
    "            else:\n",
    "                dAlpha = -eta * np.array(dE_dAlpha)\n",
    "\n",
    "            # update parameters\n",
    "            for varsWithMemFuncs in range(len(self.memFuncs)):\n",
    "                for MFs in range(len(self.memFuncsByVariable[varsWithMemFuncs])):\n",
    "                    paramList = sorted(self.memFuncs[varsWithMemFuncs][MFs][1])\n",
    "                    for param in range(len(paramList)):\n",
    "                        self.memFuncs[varsWithMemFuncs][MFs][1][paramList[param]] \\\n",
    "                        = self.memFuncs[varsWithMemFuncs][MFs][1][paramList[param]] \\\n",
    "                        + dAlpha[varsWithMemFuncs][MFs][param]\n",
    "            epoch = epoch + 1\n",
    "\n",
    "\n",
    "        self.fittedValues = self.predict(self.X)\n",
    "        self.residuals = self.Y - self.fittedValues[:,0]\n",
    "\n",
    "    def plotErrors(self):\n",
    "        \"\"\"\n",
    "        Show training error vs epoch number\n",
    "        \"\"\"\n",
    "        if self.trainingType == 'Not trained yet':\n",
    "            print(self.trainingType)\n",
    "        else:\n",
    "            plt.plot(range(1, len(self.errors)+1),self.errors,'ro', label='errors')\n",
    "            plt.ylabel('error')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.title('Training error vs. epoch number')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "    def plotMF(self, x, inputVar):\n",
    "        \"\"\"\n",
    "        Plot graph of membership function\n",
    "        x: 1-D array\n",
    "        inputVar: index of variable, of which we take membership functions\n",
    "        \"\"\"\n",
    "        for mf in range(len(self.memFuncs[inputVar])):\n",
    "            if self.memFuncs[inputVar][mf][0] == 'gaussmf':\n",
    "                y = gaussmf(x,**self.memClass.MFList[inputVar][mf][1])\n",
    "            elif self.memFuncs[inputVar][mf][0] == 'gbellmf':\n",
    "                y = gbellmf(x,**self.memClass.MFList[inputVar][mf][1])\n",
    "            elif self.memFuncs[inputVar][mf][0] == 'sigmf':\n",
    "                y = sigmf(x,**self.memClass.MFList[inputVar][mf][1])\n",
    "            plt.plot(x,y, label='MF '+ str(mf+1))\n",
    "\n",
    "        plt.grid('True')\n",
    "        plt.title('Trained membership functions, %d variable' %(inputVar+1))\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plotResults(self):\n",
    "        \"\"\"\n",
    "        Plot predicted values vs true values\n",
    "        only for 1-D true values\n",
    "        \"\"\"\n",
    "        if self.trainingType == 'Not trained yet':\n",
    "            print(self.trainingType)\n",
    "        else:\n",
    "            plt.plot(range(len(self.fittedValues)),\n",
    "                     self.fittedValues,'r', \n",
    "                     label='trained')\n",
    "            plt.plot(range(len(self.Y)),self.Y,'b', label='original')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.title('Original and predicted values')\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "    def forwardHalfPass(self, Xs):\n",
    "        \"\"\"\n",
    "        Fuzzy neural network forward propagation from Xs (half pass)\n",
    "        return layerFour (not the last layer),\n",
    "               w and wSum: weight and sum weight for each example\n",
    "               these are for back propagation\n",
    "        \"\"\"\n",
    "        layerFour = np.empty(0,)\n",
    "        wSum = []\n",
    "\n",
    "        for pattern in range(Xs.shape[0]):\n",
    "            # pattern = X sample to run forward pass\n",
    "            \n",
    "            # layer one - fuzzification layers\n",
    "            # take the pattern-th sample and pass to the neural network\n",
    "            layerOne = self.memClass.evaluateMF(Xs[pattern,:])\n",
    "\n",
    "            # layer two\n",
    "            # len(self.rules[0]) = dimmension of each pattern\n",
    "            # len(self.rules) = number of possible rules\n",
    "            # First build all possible combinations of membership function values\n",
    "            # from [x1, x2, ..., xm]\n",
    "            \n",
    "            miAlloc = [\n",
    "                [\n",
    "                    layerOne[x][self.rules[row][x]]\n",
    "                    for x in range(len(self.rules[0]))\n",
    "                ] \n",
    "                for row in range(len(self.rules))\n",
    "            ]  # values of membership functions\n",
    "            \n",
    "            # Then take the product of each combination\n",
    "            # use .T operator to enssure that output is shaped (1, number of rules)\n",
    "            layerTwo = np.array([np.product(comb) for comb in miAlloc]).T\n",
    "            \n",
    "            # Vertically stack  \n",
    "            if pattern == 0:  # in case ONE input\n",
    "                w = layerTwo\n",
    "            else:\n",
    "                w = np.vstack((w,layerTwo))\n",
    "\n",
    "            # layer three\n",
    "            wSum.append(np.sum(layerTwo))\n",
    "            layerThree = layerTwo/wSum[pattern]\n",
    "            \n",
    "            if pattern == 0:\n",
    "                wNormalized = layerTwo/wSum[pattern]\n",
    "            else:\n",
    "                wNormalized = np.vstack((wNormalized,layerTwo/wSum[pattern]))\n",
    "\n",
    "            # prep for layer four (bit of a hack)\n",
    "            # add 1-column (bias) then append to layerFour\n",
    "            rowHolder = np.concatenate([x*np.append(Xs[pattern,:],1) \n",
    "                                        for x in layerThree])\n",
    "            layerFour = np.append(layerFour,rowHolder)\n",
    "\n",
    "        # layer four\n",
    "        layerFour = np.array(np.array_split(layerFour,pattern + 1))\n",
    "\n",
    "        return layerFour, wSum, w.T\n",
    "\n",
    "    def backprop(self, columnX, columns, theWSum, theW, theLayerFive):\n",
    "        \n",
    "        \"\"\"\n",
    "        back propagation for fuzzy neural network\n",
    "        columnX: column in input matrix self.X\n",
    "        columns: list of column indices of self.X\n",
    "        theWSum: sum of weights in forward half pass\n",
    "        theW: weights in forward half pass\n",
    "        theLayerFive: predicted value by FANN\n",
    "        \n",
    "        Return steps to update parameters in membership function list\n",
    "        \"\"\"\n",
    "\n",
    "        paramGrp = [0]* len(self.memFuncs[columnX])\n",
    "        for MF in range(len(self.memFuncs[columnX])):   \n",
    "            # for each membership function of columnX-th variable\n",
    "            \n",
    "            # get number of parameters\n",
    "            parameters = np.empty(len(self.memFuncs[columnX][MF][1]))\n",
    "            timesThru = 0\n",
    "            \n",
    "            for alpha in sorted(self.memFuncs[columnX][MF][1].keys()):\n",
    "                # for each parameter of membership function\n",
    "                \n",
    "                bucket3 = np.empty(len(self.X))\n",
    "                for rowX in range(len(self.X)):\n",
    "                    # for each sample\n",
    "                    \n",
    "                    # get value of variable (x)\n",
    "                    varToTest = self.X[rowX,columnX]   # x\n",
    "                    tmpRow = np.empty(len(self.memFuncs))\n",
    "                    tmpRow.fill(varToTest)\n",
    "\n",
    "                    bucket2 = np.empty(self.Y.ndim)\n",
    "                    for colY in range(self.Y.ndim):\n",
    "\n",
    "                        rulesWithAlpha = np.array(\n",
    "                            np.where(self.rules[:,columnX]==MF)\n",
    "                        )[0]\n",
    "                        adjCols = np.delete(columns,columnX)\n",
    "\n",
    "                        # get derivative of selected parameter alpha\n",
    "                        senSit = partial_dMF(\n",
    "                            x=self.X[rowX,columnX],\n",
    "                            mf_definition=self.memFuncs[columnX][MF],\n",
    "                            partial_parameter=alpha\n",
    "                        )\n",
    "                        \n",
    "                        # produces d_ruleOutput/d_parameterWithinMF\n",
    "                        dW_dAplha = senSit * \\\n",
    "                        np.array(\n",
    "                            [np.prod(\n",
    "                              [self.memClass.evaluateMF(tmpRow)[c][self.rules[r][c]]\n",
    "                              for c in adjCols]\n",
    "                            ) \n",
    "                            for r in rulesWithAlpha]\n",
    "                        )\n",
    "\n",
    "                        bucket1 = np.empty(self.rules.shape[0])\n",
    "                        for consequent in range(self.rules.shape[0]):\n",
    "                            # for each rule\n",
    "                            fConsequent = np.append(self.X[rowX,:],1.)\\\n",
    "                                            .dot(\n",
    "                                self.consequents[\n",
    "                                    ((self.X.shape[1] + 1) * consequent):\n",
    "                                    ((self.X.shape[1] + 1) * (consequent + 1)),\n",
    "                                    colY]\n",
    "                            )\n",
    "                            \n",
    "                            acum = 0\n",
    "                            if consequent in rulesWithAlpha:\n",
    "                                acum = dW_dAplha[np.where(rulesWithAlpha==consequent)] \\\n",
    "                                * theWSum[rowX]\n",
    "\n",
    "                            acum = acum - theW[consequent,rowX] * np.sum(dW_dAplha)\n",
    "                            acum = acum / theWSum[rowX]**2\n",
    "                            bucket1[consequent] = fConsequent * acum\n",
    "\n",
    "                        sum1 = np.sum(bucket1)\n",
    "\n",
    "                        if self.Y.ndim == 1:\n",
    "                            bucket2[colY] = \\\n",
    "                            sum1 * (self.Y[rowX]-theLayerFive[rowX,colY])*(2)\n",
    "                        else:\n",
    "                            bucket2[colY] = \\\n",
    "                            sum1 * (self.Y[rowX,colY]-theLayerFive[rowX,colY])*(2)\n",
    "\n",
    "                    sum2 = np.sum(bucket2)\n",
    "                    bucket3[rowX] = sum2\n",
    "\n",
    "                sum3 = np.sum(bucket3)\n",
    "                parameters[timesThru] = sum3\n",
    "                timesThru = timesThru + 1\n",
    "\n",
    "            paramGrp[MF] = parameters\n",
    "\n",
    "        return paramGrp\n",
    "\n",
    "\n",
    "    def predict(self, varsToTest):\n",
    "        \"\"\"\n",
    "        Calculate predicted value for varsToTest\n",
    "        The number of columns in varsToTest must equal len(self.MFList)\n",
    "        \"\"\"\n",
    "        [layerFour, wSum, w] = self.forwardHalfPass(varsToTest)\n",
    "\n",
    "        #layer five\n",
    "        layerFive = layerFour.dot(self.consequents)\n",
    "\n",
    "        return layerFive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANFIS testing\n",
    "### Preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data for model\n",
    "ts = np.loadtxt(\"/home/hung/githubtest/anfis/anfistest/trainingSet.txt\", usecols=[1,2,3])\n",
    "X = ts[:,0:2]\n",
    "Y = ts[:,2]\n",
    "\n",
    "# initialize membership function's parameters\n",
    "mf = \\\n",
    "[\n",
    "    [\n",
    "        ['gaussmf', {'mean':0.,'sigma':1.}],\n",
    "        ['gaussmf', {'mean':-1.,'sigma':2.}],\n",
    "        ['gaussmf', {'mean':-4.,'sigma':10.}],\n",
    "        ['gaussmf', {'mean':-7.,'sigma':7.}]\n",
    "    ],\n",
    "    [\n",
    "        ['gaussmf', {'mean':1.,'sigma':2.}],\n",
    "        ['gaussmf', {'mean':2.,'sigma':3.}],\n",
    "        ['gaussmf', {'mean':-2.,'sigma':10.}],\n",
    "        ['gaussmf', {'mean':-10.5,'sigma':5.}]\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2D plot\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X[:, 0], Y, label='1st var', c='b')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X[:, 1], Y, label='2nd var', c='r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(X[:, 0], label='X0')\n",
    "plt.plot(X[:, 1], label='X1')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D visulization of train data\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(xs=X[:, 0], ys=X[:, 1], zs=Y,\n",
    "           zdir='z', s=10, c=None, )\n",
    "ax.set_xlabel('X-axis')\n",
    "ax.set_ylabel('Y-axis')\n",
    "ax.set_zlabel('Z-axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "anf = ANFIS(X=X, Y=Y, memFunction=MemFuncs(mf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "anf.trainHybridJangOffLine(epochs=10, k=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot results\n",
    "anf.plotErrors()\n",
    "anf.plotResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membership function visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xx = np.array(range(-5000, 5001))/100\n",
    "yy = np.zeros((2,4,xx.shape[0]))\n",
    "color = ['c', 'm', 'y', 'k']\n",
    "for i in range(2):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Initial membership functions of %d-th variable'%(i+1))\n",
    "    for j in range(4):\n",
    "        mean = mf[i][j][1]['mean']\n",
    "        sigma = mf[i][j][1]['sigma']\n",
    "        yy[i,j,:] = gaussmf(xx, mean, sigma)\n",
    "        plt.plot(xx, yy[i][j], label='MF '+str(j+1))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    anf.plotMF(xx, i)\n",
    "# anf.memFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look into the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial membership functions' parameter\n",
    "mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained membership functions' parameter\n",
    "anf.memFuncs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The parameters changed a bit, not significantlty**\n",
    "\n",
    "### Model evaluation and comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(np.matrix(Y).transpose(), anf.predict(X)))\n",
    "print('RMSE on train:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "print('Train RMSE with Sklearn: ', np.sqrt(mean_squared_error(Y, model.predict(X))))\n",
    "\n",
    "plt.plot(Y, label='Train groud truth')\n",
    "plt.plot(model.predict(X), label='Train prediction')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the trained model by ANFIS is **better than pure linear regression model**. This is because of the nonlinearity of ANFIS. Furthermore, pure LR model has 3 parameters (two for weights and one for bias) while ANFIS has more paramerters: 16 for total 8 membership functions and 17 from LSE (transform layer 4 to layer 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model by formula\n",
    "# Y = weight*X + bias\n",
    "weight = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "bias = Y.mean()-weight.dot(X.mean(axis=0).T)\n",
    "print('Weight:', weight, '\\nBias:', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression model coefficients\n",
    "weight = model.coef_\n",
    "bias = model.intercept_\n",
    "print('Weight:', weight, '\\nBias:', bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights are closed to 0, all predicted values were **just the bias**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
